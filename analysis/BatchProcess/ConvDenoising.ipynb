{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HeadscanData import * #Import all classes\n",
    "import matplotlib.pyplot as plt\n",
    "import proplot as pplt\n",
    "import numpy as np\n",
    "from tkinter.filedialog import askdirectory\n",
    "import batchfile\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from HeadscanData import * #Import all classes\n",
    "import proplot as pplt\n",
    "import batchfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### file info ###\n",
    "batchname = 'WaterfallExperiments'\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "calnames, scannames, datapath = eval('batchfile.' + batchname + '()') #batchfile.getscannames()\n",
    "nsubjects = len(scannames)\n",
    "datapath = os.path.expanduser(datapath)\n",
    "\n",
    "numScansTot = 0\n",
    "for scanName in scannames:\n",
    "    numScansTot = numScansTot+len(scanName)\n",
    "\n",
    "dataList = [{}] * numScansTot\n",
    "subjectID = np.zeros(numScansTot)\n",
    "ind = 0\n",
    "### loop of subjects and scans\n",
    "for ii in range(nsubjects):\n",
    "    nscans = len(scannames[ii])\n",
    "        #plt.close('all')\n",
    "    for jj in range(nscans): \n",
    "        \n",
    "        print('subject ' + str(ii+1) + ',  scan ' + str(jj+1))\n",
    "    \n",
    "        ### data and algo parameters ###\n",
    "        calname = datapath + '/' + calnames[ii]\n",
    "        scanname = datapath + '/' + scannames[ii][jj]\n",
    "        \n",
    "        #Testing new object oriented code\n",
    "        scanParams  = HeadScanParams(scanname, calname)\n",
    "        subjectScan = HeadScanData(scanParams)\n",
    "        subjectScan.LoadScanDataAndPreprocess(cropTimeStart=1,cropTimeEnd=-1)\n",
    "        subjectScan.RunWaveletFilteringOnSignal()\n",
    "        if 1:#ii:\n",
    "            subjectScan.GetPulseFeatures(lowNoise=True)\n",
    "        else:\n",
    "            subjectScan.GetPulseFeatures()\n",
    "        dataList[ind] = subjectScan\n",
    "        subjectID[ind] = ii+1\n",
    "        ind = ind+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dataList[11].scanData[0].contrast, np.min(dataList[11].scanData[0].contrast, axis=0))\n",
    "array28Hz = ()\n",
    "for i in range(11,len(dataList)):\n",
    "    for scan in dataList[i].scanData:\n",
    "        curArr = scan.contrast-np.percentile(scan.contrast,0.5,axis=0)\n",
    "        curArr = curArr/np.percentile(curArr,99.5)\n",
    "        curArr = np.expand_dims(curArr,axis=0)\n",
    "        if not len(array28Hz):\n",
    "            array28Hz = curArr[:,:,0::3]\n",
    "        else:\n",
    "            array28Hz = np.concatenate((array28Hz,curArr[:,:,0::3]))\n",
    "array28Hz = np.clip(array28Hz,  0.0, 1.0)\n",
    "print(array28Hz.shape, curArr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(array, noise_factor = 0.1):\n",
    "    \"\"\"\n",
    "    Adds random noise to each image in the supplied array.\n",
    "    \"\"\"\n",
    "\n",
    "    noisy_array = array + noise_factor * np.random.normal(\n",
    "        loc=0.0, scale=1.0, size=array.shape\n",
    "    )\n",
    "\n",
    "    return np.clip(noisy_array, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def display(array1, array2, array3 = (), rowLabels = None ):\n",
    "    \"\"\"\n",
    "    Displays ten random waveforms from each one of the supplied arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    n = 3\n",
    "\n",
    "    indices = np.random.randint(len(array1), size=n)\n",
    "    wave1 = array1[indices, :, :]\n",
    "    wave2 = array2[indices, :, :]\n",
    "    if len(array3):\n",
    "        wave3 = array3[indices, :, :]\n",
    "        fig, axs = pplt.subplots(ncols=3, nrows=3,refwidth=1.5)\n",
    "    else:\n",
    "        fig, axs = pplt.subplots(ncols=3, nrows=2,refwidth=1.5)\n",
    "    axs.format(\n",
    "        grid=False, xlabel='Samples', ylabel='Normalized Contrast',\n",
    "        toplabels=('Scan 1', 'Scan 2', 'Scan 3'),\n",
    "        leftlabels=rowLabels)\n",
    "\n",
    "    for i, (wv1, wv2) in enumerate(zip(wave1, wave2)):\n",
    "        axs[i].plot(wv1, labels=['Cam 1','Cam 4'])\n",
    "        if not i:\n",
    "            fig.legend()\n",
    "        axs[i+n].plot(wv2, labels=['Cam 1','Cam 4'])\n",
    "        if len(array3):\n",
    "            axs[i+2*n].plot(np.squeeze(wave3[i,:,:]), labels=['Cam 4','Cam 4'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we only need images from the dataset to encode and decode, we\n",
    "# won't use the labels.\n",
    "train_data, test_data = train_test_split(array28Hz,test_size=0.1)\n",
    "\n",
    "# Normalize and reshape the data\n",
    "#train_data = preprocess(train_data)\n",
    "#test_data = preprocess(test_data)\n",
    "\n",
    "# Create a copy of the data with added noise\n",
    "noisy_train_data = noise(train_data,noise_factor=0.01)\n",
    "noisy_test_data = noise(test_data,noise_factor=0.01)\n",
    "\n",
    "# Display the train data and a version of it with added noise\n",
    "print(train_data.shape, test_data.shape)\n",
    "print(noisy_train_data.shape, noisy_test_data.shape)\n",
    "display(train_data, noisy_train_data, rowLabels=('Scan Data', 'Scan Data+Noise(Gaussian)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(200, 2, 1))\n",
    "\n",
    "# Encoder\n",
    "x = layers.Conv2D(32, (3, 1), activation=\"relu\", padding=\"same\")(input)\n",
    "x = layers.Conv2D(32, (3, 1), activation=\"relu\", padding=\"same\", dilation_rate=2)(x)\n",
    "x = layers.Conv2D(32, (3, 1), activation=\"relu\", padding=\"same\", dilation_rate=2)(x)\n",
    "x = layers.Conv2D(32, (3, 1), activation=\"relu\", padding=\"same\", strides=(2,1))(x)\n",
    "x = layers.Conv2D(32, (3, 1), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2D(32, (3, 1), activation=\"relu\", padding=\"same\", dilation_rate=2)(x)\n",
    "x = layers.Conv2D(32, (3, 1), activation=\"relu\", padding=\"same\", dilation_rate=2)(x)\n",
    "x = layers.Conv2D(32, (3, 1), activation=\"relu\", padding=\"same\", strides=(2,1))(x)\n",
    "x = layers.Conv2D(32, (3, 1), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2D(32, (3, 1), activation=\"relu\", padding=\"same\", dilation_rate=2)(x)\n",
    "x = layers.Conv2D(32, (3, 1), activation=\"relu\", padding=\"same\", dilation_rate=2)(x)\n",
    "x = layers.Conv2D(32, (3, 1), activation=\"relu\", padding=\"same\", strides=(2,1))(x)\n",
    "x = layers.Conv2D(32, (3, 1), activation=\"relu\", padding=\"same\", dilation_rate=2)(x)\n",
    "x = layers.Conv2D(32, (3, 1), activation=\"relu\", padding=\"same\", dilation_rate=2)(x)\n",
    "# Decoder\n",
    "x = layers.Conv2DTranspose(32, (3, 1), activation=\"relu\", padding=\"same\", dilation_rate=2)(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 1), activation=\"relu\", padding=\"same\", dilation_rate=2)(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 1), strides=(2,1), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 1), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 1), activation=\"relu\", padding=\"same\", dilation_rate=2)(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 1), activation=\"relu\", padding=\"same\", dilation_rate=2)(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 1), strides=(2,1), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 1), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 1), activation=\"relu\", padding=\"same\", dilation_rate=2)(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 1), activation=\"relu\", padding=\"same\", dilation_rate=2)(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 1), strides=(2,1), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 1), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 1), activation=\"relu\", padding=\"same\", dilation_rate=2)(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 1), activation=\"relu\", padding=\"same\", dilation_rate=2)(x)\n",
    "x = layers.Conv2D(1, (3, 1), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder = Model(input, x)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=tf.keras.losses.MeanSquaredError())#\"binary_crossentropy\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(\n",
    "    x=train_data,\n",
    "    y=train_data,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_data=(test_data, test_data),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(test_data)\n",
    "print(predictions.shape)\n",
    "display(test_data, np.squeeze(predictions), rowLabels=('Scan Data', 'Reconstructed Scan Data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(\n",
    "    x=noisy_train_data,\n",
    "    y=train_data,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_data=(noisy_test_data, test_data),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(noisy_test_data)\n",
    "display(noisy_test_data, np.squeeze(predictions), test_data, rowLabels=('Noisy', 'Reconstructed','Scan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b15711da9d587583d2e55c33647bc6b57c46b32b5485268373dd91cd590dcdad"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
